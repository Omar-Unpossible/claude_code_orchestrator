"""Add LLM-first framework tables

Revision ID: bcb1fdee05a9
Revises: 1a6a70f64ea3
Create Date: 2025-11-03 16:29:24.173610

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = 'bcb1fdee05a9'
down_revision: Union[str, Sequence[str], None] = '1a6a70f64ea3'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('complexity_estimate',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('task_id', sa.Integer(), nullable=False),
    sa.Column('estimated_tokens', sa.Integer(), nullable=False),
    sa.Column('estimated_loc', sa.Integer(), nullable=False),
    sa.Column('estimated_files', sa.Integer(), nullable=False),
    sa.Column('estimated_duration_minutes', sa.Integer(), nullable=False),
    sa.Column('overall_complexity_score', sa.Integer(), nullable=False),
    sa.Column('heuristic_score', sa.Integer(), nullable=False),
    sa.Column('llm_adjusted_score', sa.Integer(), nullable=True),
    sa.Column('should_decompose', sa.Boolean(), nullable=False),
    sa.Column('decomposition_reason', sa.Text(), nullable=True),
    sa.Column('actual_tokens', sa.Integer(), nullable=True),
    sa.Column('actual_loc', sa.Integer(), nullable=True),
    sa.Column('actual_files', sa.Integer(), nullable=True),
    sa.Column('actual_duration_minutes', sa.Integer(), nullable=True),
    sa.Column('estimation_accuracy', sa.Float(), nullable=True),
    sa.Column('estimation_factors', sa.JSON(), nullable=True),
    sa.Column('confidence', sa.Float(), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=False),
    sa.Column('updated_at', sa.DateTime(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=False),
    sa.CheckConstraint('confidence >= 0.0 AND confidence <= 1.0', name='check_confidence_range'),
    sa.CheckConstraint('overall_complexity_score >= 0 AND overall_complexity_score <= 100', name='check_complexity_range'),
    sa.ForeignKeyConstraint(['task_id'], ['task.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_complexity_should_decompose', 'complexity_estimate', ['should_decompose', 'overall_complexity_score'], unique=False)
    op.create_index(op.f('ix_complexity_estimate_should_decompose'), 'complexity_estimate', ['should_decompose'], unique=False)
    op.create_index(op.f('ix_complexity_estimate_task_id'), 'complexity_estimate', ['task_id'], unique=True)
    op.create_table('parallel_agent_attempt',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('task_id', sa.Integer(), nullable=False),
    sa.Column('num_agents', sa.Integer(), nullable=False),
    sa.Column('agent_ids', sa.JSON(), nullable=False),
    sa.Column('subtask_ids', sa.JSON(), nullable=False),
    sa.Column('success', sa.Boolean(), nullable=False),
    sa.Column('failure_reason', sa.Text(), nullable=True),
    sa.Column('conflict_detected', sa.Boolean(), nullable=False),
    sa.Column('conflict_details', sa.JSON(), nullable=True),
    sa.Column('total_duration_seconds', sa.Float(), nullable=False),
    sa.Column('sequential_estimate_seconds', sa.Float(), nullable=True),
    sa.Column('speedup_factor', sa.Float(), nullable=True),
    sa.Column('max_concurrent_agents', sa.Integer(), nullable=False),
    sa.Column('total_token_usage', sa.Integer(), nullable=True),
    sa.Column('failed_agent_count', sa.Integer(), nullable=False),
    sa.Column('parallelization_strategy', sa.String(length=100), nullable=False),
    sa.Column('fallback_to_sequential', sa.Boolean(), nullable=False),
    sa.Column('execution_metadata', sa.JSON(), nullable=True),
    sa.Column('started_at', sa.DateTime(), nullable=False),
    sa.Column('completed_at', sa.DateTime(), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=False),
    sa.CheckConstraint('num_agents >= 2', name='check_min_agents'),
    sa.CheckConstraint('speedup_factor > 0', name='check_positive_speedup'),
    sa.ForeignKeyConstraint(['task_id'], ['task.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_parallel_success_strategy', 'parallel_agent_attempt', ['success', 'parallelization_strategy'], unique=False)
    op.create_index(op.f('ix_parallel_agent_attempt_started_at'), 'parallel_agent_attempt', ['started_at'], unique=False)
    op.create_index(op.f('ix_parallel_agent_attempt_success'), 'parallel_agent_attempt', ['success'], unique=False)
    op.create_index(op.f('ix_parallel_agent_attempt_task_id'), 'parallel_agent_attempt', ['task_id'], unique=False)
    op.create_table('prompt_rule_violation',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('task_id', sa.Integer(), nullable=False),
    sa.Column('rule_id', sa.String(length=50), nullable=False),
    sa.Column('rule_name', sa.String(length=255), nullable=False),
    sa.Column('rule_domain', sa.String(length=50), nullable=False),
    sa.Column('violation_details', sa.JSON(), nullable=False),
    sa.Column('severity', sa.String(length=20), nullable=False),
    sa.Column('resolved', sa.Boolean(), nullable=False),
    sa.Column('resolution_notes', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=False),
    sa.Column('resolved_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['task_id'], ['task.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_violation_severity_resolved', 'prompt_rule_violation', ['severity', 'resolved'], unique=False)
    op.create_index('idx_violation_task_rule', 'prompt_rule_violation', ['task_id', 'rule_id'], unique=False)
    op.create_index(op.f('ix_prompt_rule_violation_created_at'), 'prompt_rule_violation', ['created_at'], unique=False)
    op.create_index(op.f('ix_prompt_rule_violation_resolved'), 'prompt_rule_violation', ['resolved'], unique=False)
    op.create_index(op.f('ix_prompt_rule_violation_rule_domain'), 'prompt_rule_violation', ['rule_domain'], unique=False)
    op.create_index(op.f('ix_prompt_rule_violation_rule_id'), 'prompt_rule_violation', ['rule_id'], unique=False)
    op.create_index(op.f('ix_prompt_rule_violation_severity'), 'prompt_rule_violation', ['severity'], unique=False)
    op.create_index(op.f('ix_prompt_rule_violation_task_id'), 'prompt_rule_violation', ['task_id'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_prompt_rule_violation_task_id'), table_name='prompt_rule_violation')
    op.drop_index(op.f('ix_prompt_rule_violation_severity'), table_name='prompt_rule_violation')
    op.drop_index(op.f('ix_prompt_rule_violation_rule_id'), table_name='prompt_rule_violation')
    op.drop_index(op.f('ix_prompt_rule_violation_rule_domain'), table_name='prompt_rule_violation')
    op.drop_index(op.f('ix_prompt_rule_violation_resolved'), table_name='prompt_rule_violation')
    op.drop_index(op.f('ix_prompt_rule_violation_created_at'), table_name='prompt_rule_violation')
    op.drop_index('idx_violation_task_rule', table_name='prompt_rule_violation')
    op.drop_index('idx_violation_severity_resolved', table_name='prompt_rule_violation')
    op.drop_table('prompt_rule_violation')
    op.drop_index(op.f('ix_parallel_agent_attempt_task_id'), table_name='parallel_agent_attempt')
    op.drop_index(op.f('ix_parallel_agent_attempt_success'), table_name='parallel_agent_attempt')
    op.drop_index(op.f('ix_parallel_agent_attempt_started_at'), table_name='parallel_agent_attempt')
    op.drop_index('idx_parallel_success_strategy', table_name='parallel_agent_attempt')
    op.drop_table('parallel_agent_attempt')
    op.drop_index(op.f('ix_complexity_estimate_task_id'), table_name='complexity_estimate')
    op.drop_index(op.f('ix_complexity_estimate_should_decompose'), table_name='complexity_estimate')
    op.drop_index('idx_complexity_should_decompose', table_name='complexity_estimate')
    op.drop_table('complexity_estimate')
    # ### end Alembic commands ###
